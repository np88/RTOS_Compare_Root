\chapter{Benchmarking}
Vergleichskriterien für Betriebssysteme:
\begin{itemize}
	\item Performanz
	\item Sicherheit
	\item Ressourcen-/Speicherverbrauch
	\item Speicherverwaltung
\end{itemize}

\section{Performanz}
\begin{enumerate}
	\item Latenzzeiten/Jitter
		\begin{enumerate}
			\item Interrupt durch Taster $ \rightarrow $ Aufblinken von LED (die Zeit, die dasAufblinken benötigt, kann gemessen und abgezogen werden, so dass nur die Zeit vom Drücken des Tasters bis zum Ausführen der ISR bleibt)
			\item Andere Interruptquellen? ( $ \rightarrow $ z.B CAN, Ethernet, SPI, ...)
			\item Verschiedene Taktzeiten von FreeRTOS
		\end{enumerate}
	\item Durchsatz an Daten
		\begin{enumerate}
			\item Ethernet
			\item CAN
			\item SPI
		\end{enumerate}	
	\item Bootzeit
		\begin{enumerate}
			\item Was hat Einwirkungen auf die Bootzeit?
			\item Indikatoren $ \rightarrow $ Wann ist das System hochgefahren?
			\item Bestimmtes Programm wird gestartet $ \rightarrow $ z.B. Aufleuchten von LED
			\item Bestimmte Programme können den Bootvorgang aufzeichen (Bootchart)  
		\end{enumerate}			
\end{enumerate}

\subsection{Latenzzeiten von Interrupts}
Für die Latenzzeit von Interrupts soll ein Interrupt von einer externen Quelle ausgelöst werden und dann wird gemessen, wann die Interruptserviceroutine betreten wird. Konkret wird periodisch ein GPIO-Interrupt durch einen Signalgenerator in Hardware ausgelöst. Die GPIO wird über das EMIO-Interface angebunden. In der dazugehörigen ISR wird eine LED angeschaltet. Es wird die Zeit zwischen dem Setzen des Interruptsignals und aufblinken der LED gemessen. Von dieser Zeit muss abgezogen werden, wie lange das Anschalten der LED und die Zeitmessung an sich dauert. Grundsätzlich wird jede Messung 1024 Mal durchgeführt. Für die Zusatzmessungen sind die Durchschnittszeiten interessant. Für die Hauptmessung ist zusätzlich der Worst-Case-Fall zu beachten.
 
\subsubsection{FreeRTOS}
Bei FreeRTOS werden die Interrupts unabhängig vom Betriebssystem verwaltet. Der EMIO-GPIO-Interrupt hat nach dem System-Timer die höchste Priorität. 
\\\\Axi-Timer: 50 MHz

Ergebnis: 

\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|}
			\hline
			 Anz. Messungen &  19100 \\	
			\hline
			 Durchschnittswert & 754,8ns \\
			\hline
			 Standardabweichung &  8,5977ns (19.31 ns) \\
			\hline
			 Minimalwert & 740ns \\
			\hline	
			 Maximalwert &  780ns \\
			\hline
			 Durchschnittswert LED-Anschalten &  700-740ns (130 ns)\\
			\hline
			 Durchschnittswert Timer-Overhead &  520ns (9ns) \\
			\hline				
			LED-Overhead bei ISR-Messung & 220ns (121 ns)\\
			\hline		
			Durchschnitt - Overhead & 633,8ns \\
			\hline	
			Durchschnitt - Overhead (Taktzyklen) & 422 Zyklen\\
			\hline								
		\end{tabular}
		\label{theap1}
\end{table*}

mit Task:
\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|}
			\hline
			 Anz. Messungen &  19100 \\	
			\hline
			 Durchschnittswert & 754,8ns \\
			\hline
			 Standardabweichung &  8,5977ns (19.31 ns) \\
			\hline
			 Minimalwert & 719ns \\
			\hline	
			 Maximalwert & 840ns \\
			\hline
			 Durchschnittswert LED-Anschalten &  700-740ns (130 ns)\\
			\hline
			 Durchschnittswert Timer-Overhead &  520ns (9ns) \\
			\hline				
			LED-Overhead bei ISR-Messung & 220ns (121 ns)\\
			\hline		
			Durchschnitt - Overhead & 633,8ns \\
			\hline	
			Durchschnitt - Overhead (Taktzyklen) & 422 Zyklen\\
			\hline								
		\end{tabular}
		\label{theap1}
\end{table*}

\subsubsection{LinuxRT}
Messung mit wmb():
Ergebnis: 
\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|}
			\hline
			 Anz. Messungen &  19160 \\	
			\hline
			 Durchschnittswert & 13,569us \\
			\hline
			 Standardabweichung &  1,4412us \\
			\hline
			 Minimalwert & 8us \\
			\hline	
			 Maximalwert &  28,8us \\
			\hline
			 Durchschnittswert LED-Anschalten &   \\
			\hline
			 Durchschnittswert Timer-Overhead &   \\
			\hline				
			LED-Overhead bei ISR-Messung &  \\
			\hline		
			Durchschnitt - Overhead & s \\
			\hline	
			Durchschnitt - Overhead (Taktzyklen) & \\
			\hline								
		\end{tabular}
		\label{theap1}
\end{table*}

Messung ohne wmb():
Ergebnis: 
\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|}
			\hline
			 Anz. Messungen &  19130 \\	
			\hline
			 Durchschnittswert & 13,406us \\
			\hline
			 Standardabweichung &  1,3419us \\
			\hline
			 Minimalwert & 8,6us \\
			\hline	
			 Maximalwert &  32us \\
			\hline
			 Durchschnittswert LED-Anschalten &   \\
			\hline
			 Durchschnittswert Timer-Overhead &   \\
			\hline				
			LED-Overhead bei ISR-Messung &  \\
			\hline		
			Durchschnitt - Overhead & s \\
			\hline	
			Durchschnitt - Overhead (Taktzyklen) & \\
			\hline								
		\end{tabular}
		\label{theap1}
\end{table*}

Messung For-Loops in Zyklen:
\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|l|}
			\hline	
			For-Loop 0 & Runden 16 &  180  \\
			\hline	
			For-Loop 1 & Runden 32 &  304  \\
			\hline	
			For-Loop 2 & Runden 64 &  533 \\
			\hline	
			For-Loop 3 & Runden 128 &  1045  \\
			\hline	
			For-Loop 4 & Runden 264 &  2133  \\
			\hline	
			For-Loop 5 & Runden 512 &  4117  \\
			\hline	
			For-Loop 6 & Runden 1024 &  8213  \\
			\hline	
			For-Loop 7 & Runden 2048 &  16405  \\
			\hline	
			For-Loop 8 & Runden 4096 &  32789  \\
			\hline	
			For-Loop 9 & Runden 8192 & 65557  \\
			\hline	
		\end{tabular}
		\label{theap1}
\end{table*}

Messung While-Loops in Zyklen:
\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|l|l|}
			\hline	
			Loop 0 & Runden 16 &  171  \\
			\hline	
			Loop 1 & Runden 32 & 301 \\
			\hline	
			Loop 2 & Runden 64 &  535 \\
			\hline	
			Loop 3 & Runden 128 &  1047  \\
			\hline	
			Loop 4 & Runden 264 &  2135  \\
			\hline	
			Loop 5 & Runden 512 &  4119  \\
			\hline	
			Loop 6 & Runden 1024 &  8215  \\
			\hline	
			Loop 7 & Runden 2048 &  16407  \\
			\hline	
			Loop 8 & Runden 4096 &  32791  \\
			\hline	
			Loop 9 & Runden 8192 & 65559  \\
			\hline	
		\end{tabular}
		\label{theap1}
\end{table*}
\\Overhead Timer-Messung: $ 6 Zyklen $
\\Overhead Registerzuweisung: $ 19 - 6 = 13 Zyklen = 19 ns $
\\Messung der Registerzuweisung mit wmb()\footnote{wmb(These functions insert hardware memory barriers in the compiled instruction flow; their actual instantiation is platform dependent. An rmb (read memory barrier) guarantees that any reads appearing before the barrier are completed prior to the execution of any subsequent read. wmb guarantees ordering in write operations, and the mbinstruction guarantees both. Each of these functions is a superset of barrier). Das bedeutet, dass die Schreiboperationen auf die Hardware bis zu dieser Barriere abgeschlossen sein müssen und man davon ausgehen kann, dass der Hardwarezugriff bereits erfolgt ist. Somit kann man messen, wie lange ein Hardwarezugriff zum Beschreiben einer LED dauert und diese Zeit von der Gesamtzeit abziehen. Um ein sinnvolles Ergebnis zu erhalten, sollte auch die Messung mit wmb() arbeiten. } 

\subsection{Unterbrechung von Task durch ISR}
Ein Task läuft und speichert in einer While-Schleife immer die aktuelle Zeit. Er wird durch eine ISR unterbrochen. Sobald der Task wieder anläuft, wird wieder die Zeit gemessen. Die gesuchte Zeit ist die Different aus Start- und Endzeit.
\\\\Die übliche Methode für Interrupt Service Routinen in FreeRTOS ist, einen hochpriorisierten Task laufen zu lassen, der an einem binären Semaphor blockiert. Wird die ISR aufgerufen, wird dieser Task wieder deblockiert. 
 

\section{RT-Features}
	\begin{enumerate}
		\item Welche Unterschiede/Gemeinsamkeiten gibt es zwischen FreeRTOS und Linux?
		\item Prioritäten 
		%\item Semaphore
		%\item Message Passing (s. Semaphore)
		%\item Queues (s. Semaphore)
		\item Flags (s. Semaphore)
		\item Posix-Features in Linux
	\end{enumerate}
	
\subsection{RT-Features von Linux/Posix}
\subsubsection{Threads}
Threads in Unix sind Teile von Prozessen. Allerdings hat ein Thread einen eigenen Stack Pointer, eigene Register, Scheduling Properties, Signale und andere Daten. Ein Thread existiert, solange der Elternprozess existiert. Ein Prozess kann mehrere Threads haben. Es kann Datenaustausch von Threads im Rahmen eines Prozesses geben. Ein Thread verbraucht deutlich weniger Ressourcen als ein Prozess. Inter-Thread-Kommunikation ist deutlich schneller, weil alles in einem Adressraum stattfindet. Bei Inter-Prozess-Kommunikation ist mindestens ein Kopiervorgang von Prozess zu Prozess erforderlich.  
\subsubsection{Mutexes}
An Mutexen kann geblockt werden, aber es kann auch ausprobiert werden, ob sie bereits gelockt sind, und dann kann was anderes gemacht werden. 
\subsubsection{Conditions}
Conditions werden im Zusammenhang mit Mutexen benutzt und dienen zur Synchronisation von mehreren Threads, die Datenabhängig sind. Zur Benutzung: An einer Condition kann gewartet werden. Zuvor muss ein bestimmter Mutex genommen worden sein. Wenn man den Befehl \textit{pthread\_cond\_wait} ausführt, dann wird damit gewartet und der Mutex automatisch losgelassen. Ein anderer Thread kann sich denselben Mutex holen und dann eine bestimmte Datenverarbeitung an einer Variable durchführen. Wenn dadurch die Bedingung erfüllt wird, ruft dieser Thread die Funktion \textit{pthread\_cond\_signal}, die den anderen Thread aufweckt, sobald der Mutex losgelassen wurde. 
\subsubsection{Join}
Threads können \textit{gejoint} werden. Dieses ist ein Synchronisationsmechanismus von PThreads. Wird  \textit{pthread\_join} aufgerufen, blockiert der aktuelle Thread, bis der zu synchronisierende Thread beendet ist. 
\subsubsection{Message queues}
\textit{mqd\_t}. Eine Queue muss erst erstellt werden. \textit{mq\_send} und \textit{mq\_receive} können blockend und nicht blockend aufgerufen werden, indem das Flag \textit{O\_NONBLOCK} gesetzt wird. Tasks können außerdem darüber informiert werden, dass eine Message in der Queue abgelegt wurde. Dieses funktioniert über \textit{mq\_notify}. Darüber kann ein Handler installiert werden, der ausgeführt wird, wenn eine neue Nachricht empfangen wird. Wenn ein anderer Task mit \textit{mq\_receive} an der Queue blockiert, dann wird kein Signal verschickt und der Handler nicht ausgelöst. 
\subsubsection{Scheduling}
\textit{schedPxLib}
\textit{sched\_getScheduler}, gibt entweder SCHED\_FIFO oder SCHED\_RR zurück.
\textit{sched\_get\_priority\_max}
\textit{sched\_get\_priority\_max}
sched\_rr\_get\_interval
\subsubsection{Semaphores}
\textit{semPxLib}. Posix Semaphores sind zählende Semaphore. Die unterstützen Funktionen sind Prioritätsvererbung, rekurive Semaphore, Timeouts, ... . Posix Mutexes und Condition variables wurden implementiert, indem standardmäßige Semaphore verwendet wurden. 

	
\subsection{RT-Features von FreeRTOS}
Relevante Features:
\subsubsection{Tasks}
Tasks unter FreeRTOS können mit verschiedenen Prioritäten erstellt werden. Der idleTask hat immer die niedrigste Priorität. Tasks haben verschiedene Zustände:
\begin{itemize}
	\item Running: Task wird ausgeführt. Es kann zur Zeit nur einen einzigen Task geben, der gerade ausgeführt wird.  
	\item Ready: Wartet darauf, ausgeführt zu werden, da ein anderer Task gerade vom Scheduler gescheduled wurde
	\item Blocked: Task wartet auf ein Ereignis und wird nicht ausgeführt. Grund kann ein Delay oder das Warten an einer Queue oder einem Semaphor sein.
	\item Suspended: Ein Task wurde von einem anderen Task oder sich selber suspendiert. Dieser Status kann nur durch einen Aufruf der Funktion \textit{xTaskResume} fortgesetzt werden. 
\end{itemize}

\subsubsection{Scheduling Policy}
Die Policy wird \textit{Fixed Priority Preemptive Scheduling} genannt. Jedem Task wird eine eigene Priorität zugewiesen, wobei Tasks auch die gleiche Priorität haben können. Für jede Priorität existiert eine eigene Liste. 


\subsubsection{Queues}
Queues werden benutzt, um Nachrichten zwischen Tasks auszutauschen. Von einer Queue kann zerstörend oder nicht zerstörend gelesen werden und drauf geschrieben werden. Wenn ein Task an einer Queue wartet, kann er für eine bestimmte Zeit blockiert werde. Eine Queue kann mit unterschiedlichen Größen erzeugt werden. Es gibt auch sogenannte Queue-Sets, die es ermöglichen an mehreren Queue oder auch Semaphoren zu warten.

\subsubsection{Semaphore}
Es gibt drei verschiedene Arten von Semaphoren (s. \ref{semaphore_shuffling_time}), Mutexe, binäre Semaphore und Counting Semaphors. Semaphore werden als Queue implementiert. Werden Semaphore als Mutexe verwendet, ist die Prioritätsvererbung ebenfalls verfügbar. Ein Task kann immer nur an einem Mutex warten, da die Implementierung der Mutexe relativ simpel ist. Wenn ein Mutex von einem niederprioren Task losgelassen wird, kriegt er automatisch seine ursprüngliche Priorität zurück. Die zur Prioritätsvererbung gehörigen Code-Teile werden über Präprozessormacros eingebunden. Sollten also keine Mutexe verwendet werden, sollte das Macro auf jeden Fall auf undefiniert bleiben.
	
	
	
\subsection{Task Switching}
Unter Task Switching versteht man die Zeit, die der Scheduler braucht, um von einem Task zu einem anderen zu wechseln. Dieser Wechsel wird nach der Scheduling-Strategie des Schedulers vollzogen, d.h. der Task wird nicht etwa durch einen Interrupt oder durch einen höher prioren Task unterbrochen.
\subsubsection{FreeRTOS}
\paragraph{Variante 1}
Es werden zwei Tasks \textit{Task1} und \textit{Task2} erzeugt. Diese Tasks haben einen Workload, der darin besteht, in einer For-Schleife eine Variable hoch zu zählen. Nach jedem Inkrementieren der Variable wird ein Context-Switch erzwungen (mit taskYIELD()). Wenn die Variable eine bestimmte Höhe erreicht hat, wird das Experiment beendet. Es wird dabei die Zeit gemessen, die zwischen dem Betreten des ersten Tasks und dem Verlassen des letzten Tasks vergeht. Ein Task-Switch trifft also zwei Mal so häufig auf, wie die Schleife durchgelaufen wird. 
\\\\Von der gemessenen Zeit muss noch der eigentliche Workload abgezogen werden. Dafür werden vor dem Starten der Tasks zwei For-Schleifen durchlaufen mit der gleichen Anzahl an Durchgängen wie in den Tasks.
\paragraph{Variante 2}
Es werden zwei Tasks erzeugt, in denen eine For-Schleife mit der Anzahl der Testdurchläufe ausgeführt wird. In der Schleife befindet sich in der Reihenfolge:
\begin{itemize}
	\item Starte Messung
	\item Erzwinge Task-Switch mit taskYield()
	\item Stoppe Messung
\end{itemize}
Der Vorteil an dieser Methode ist, dass es keinen Overhead gibt. Diese Messung ist also genauer. Von dem Ergebnis muss noch die Messzeit von sechs Zyklen abgezogen werden. Zu beachten ist, dass beide Tasks damit beginnen, die Startzeit der Messung zu speichern. Das führt dazu, dass die erste Startzeit überschrieben wird. Die letzte Startzeit ist dafür ungültig und darf nicht in dem Endergebnis berücksichtigt werden. 

\subsection{Preemption-Zeit}
Die Preemption-Zeit ist die Zeit, die benötigt wird, um einen Task-Switch zu vollziehen, wenn ein niederpriorer Task durch einen Interrupt oder durch einen höher priorisierten Task oder einen Interrupt unterbrochen wird. Das bedeutet, der Scheduler wird außerhalb des regulären Tick-Interrupts aufgerufen.
\subsubsection{FreeRTOS}
Ein niederpriorer Task verrichtet Arbeit. Dieser Task wird nach einer bestimmten Zeit von einem höher  priorisierten Task unterbrochen. Es gibt zwei Funktionen in FreeRTOS, um einen Delay herbeizuführen: \textit{vTaskDelay} und \textit{vTaskDelayUntil}. \textit{vTaskDelay} wacht nach einer bestimmten Anzahl von Ticks auf. Um die Zeit zu messen, kann die Startzeit in einer Endlosschleife im arbeitenden Task dauerhaft ausgelesen werden. Wenn der Task unterbrochen wird, wurde die aktuellste Zeit vorher gespeichert. Sobald der höher priorisierte Task aufgewacht ist, wird wieder die Zeit gemessen. Das \textit{vTaskDelayUntil} wird nur jeden Tick ausgeführt. 
\\\\Eine andere Möglichkeit, die Preemption Zeit zu messen, ist, dass ein hochpriorer Task sich selbst verabschiedet und hinterher von einem niederprioren Task aufgeweckt wird. Dieses führt direkt zu einem Context-Switch.
\\\\Noch eine Möglichkeit ist es, einen hoch priorisierten Task 1 zu suspendieren und dann einen niedriger priorisieren Task 2 laufen zu lassen. Während der Task 2 läuft, wird ein Interrupt ausgelöst, der Task 1 fortsetzt und somit einen Context-Switch erzeugt.
\subsubsection{Linux}

\subsection{Semaphor Shuffle Time}\label{semaphore_shuffling_time}
Die Semaphor Shuffle Time ist die Zeit, die ein Task braucht, um an einem von einem anderen Task genommenem Semaphor aufzuwachen, wenn dieser wieder losgelassen wird. Dieser Versuch kann durchgeführt werden, indem ein Task einen Semaphor nimmt und danach ein Context-Switch durchgeführt wird.

\subsection{Message Passing}
Task 1 wartet auf eine Nachricht, Task 2 schickt eine Nachricht, Task 1 wacht auf und empfängt die Nachricht.
\subsubsection{FreeRTOS}
Messages werden durch Queues implementiert.
\subsubsection{Linux}
	
\subsection{DLB Time}
Die Deadlock breaking time ist die Zeit, die benötigt wird, um einen potenziellen Deadlock durch Prioritätsvererbung aufzulösen. Folgendes Beispiel der Prioritätsinverion verdeutlicht die Wichtigkeit der Prioritätsvererbung:
Ein niederpriorer Task greift nach einem Mutex M. Dann wird er von einem mittelprioren Task unterbrochen. Dieser wiederum wird von einem hochprioren Task unterbrochen, welcher ebenfalls nach dem Mutex M greift und blockiert. Damit wird wieder Task 2 aufgerufen, welcher nun für immer Task 1 und damit auch den Mutex M blockiert, sodass der höher priorisierte Task niemals ausgeführt wird.
\\\\Mit der Prioritätsvererbung bekommt Task 1 vorübergehend die Priorität von Task 3. Damit kann er nicht von Task 2 blockiert werden und nach getaner Arbeit den Mutex wieder freigeben. Damit kann der hoch priore Task seine Arbeit verrichten.

\subsubsection{FreeRTOS}
Es werden zwei Tasks erzeugt: Task 1 und Task 3. Task 3 ist der hochpriore Task und legt sich direkt schlafen. Task eins läuft in einer Schleife. Zuerst nimmt er sich den Mutex, dann startet er Task 2. Task 2 hat die mittlere Priorität und setzt Task 3 fort. Task 3 versucht nun nach dem Mutex zu greifen und wird blockiert. Da für Mutexe in FreeRTOS eine Prioritätsvererbung stattfindet, wird wie erwartet Task 1 fortgesetzt und gibt den Mutex wieder frei. Es wird die Zeit gemessen, ab der Task 3 versucht, auf den Mutex zuzugreifen, bis der Mutex freigegeben und der Task deblockiert wird. 

\subsubsection{Linux}  	
 	
\section{Speicherzugriffe}
	\begin{enumerate}		
		\item Speicherplatzverbrauch des gesamten Systems
		\item MPU-Unterstützung
		\item In welchem Rahmen sind dynamische Speicherzugriffe möglich?
		\item Ggf. Zeitverbrauch bei Speicherallokation/-fragmentierung
			\begin{enumerate}		
				\item Allokation von z.B. 1000 Paketen und Messen der Zeit
				\item Vergleich von Context Switch mit Speicher Allokation und ohne (?)
				\item Vergleich von verschiedenen Methoden der Speicherallokation $ \rightarrow $ Was ist der Worst Case, der passieren kann?
			\end{enumerate}
	\end{enumerate}
	
\subsection{FreeRTOS}
Es gibt immer eine Mindestfrakturgröße. Außerdem sind die Funktionen Thread-Save, d.h. können durch keinen anderen Task unterbrochen werden. Ausnahmen davon bildet je nach Implementierung Fall 3.

\subsubsection{Heap\_1.c}
Blöcke werden allokiert, wenn genug Speicher da ist und nie wieder freigegeben.

\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|p{11cm}|}
			\hline
			 Zugriffszeit & Konstant \\	
			\hline
			 Worst Case & Nicht mehr genügend Speicher vorhanden  \\
			\hline
			 Schlussfolgerung & Schnell, aber vorher überlegen, ob der Speicher für die Lebensdauer der Anwendung reicht. \\
			\hline
			 Testfall & Einfaches Allozieren, da kein Rechenaufwand durch Freigaben notwendig. \\
			\hline	
		\end{tabular}
		\label{theap1}
\end{table*}


\subsubsection{Heap\_2.c}
Es gibt eine minimale Blockgröße. Es gibt eine Liste, in der die Blöcke nach Größe sortiert sind. Es wird immer der nächst größte Block alloziert $ \rightarrow $Iteration durch Liste. Kein Verschmelzen von Blocks bei Freigabe. Zu große Blocks werden aufgeteilt. Der neu entstandene Block wird wieder in die Liste einsortiert. Nur sinnvoll, wenn der allozierte Speicher immer in etwa die gleiche Größe hat. 

\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|p{11cm}|}
			\hline
			 Zugriffszeit & Am Anfang konstant, weil nur ein Block. Sobald die Liste mehrere Elemente besitzt, ist die Zugriffszeit linear abhängig von der Länge der Liste. \\	
			\hline
			 Worst Case & Nicht mehr genügend Speicher vorhanden oder es ist Speicher vorhanden, aber nicht mehr an einem Stück oder es gibt sehr viele kleine Segmente in der Liste und nur ein größeres ganz hinten  \\
			\hline
			 Schlussfolgerung & Durch Freigaben langsamer als in Fall eins. Nicht sinnvoll, wenn allozierte Blockgröße variiert.\\
			\hline
			 Testfall &  Allozieren von möglichst vielen minimal großen Blöcken und einem, der die doppelte Größe hat. Alle wieder freigeben $ \rightarrow $ Lange Liste mit vielen Einträgen $ \rightarrow $ Nochmal den größeren Block allozieren. Die Zeit für die Längste Freigabe kann auch gemessen werden. \\
			\hline	
		\end{tabular}
		\label{theap2}
\end{table*}

\subsubsection{Heap\_3.c}
Maskierte malloc und free Aufrufe des jeweiligen Compilers.

\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|p{11cm}|}
			\hline
			 Zugriffszeit &  \\	
			\hline
			 Worst Case &  \\
			\hline
			 Schlussfolgerung & \\
			\hline
			 Testfall &  \\
			\hline	
		\end{tabular}
		\label{theap3}
\end{table*}

\subsubsection{Heap\_4.c}
Liste mit Blockzeigern und Blockgröße. Liste wird durchsucht, bis ein passendes Element gefunden wird. Bei Freigabe werden nebeneinander liegende Blöcke wieder zusammengeführt.

\begin{table*}[htb]
	\centering
		\begin{tabular}{|l|p{11cm}|}
			\hline
			 Zugriffszeit & Wie in Fall zwei, aber insgesamt schneller, da Blöcke bei der Freigabe wieder zusammengeführt werden und insgesamt tendenziell weniger Blöcke durchiteriert werden müssen.\\	
			\hline
			 Worst Case & Wie in Fall zwei\\
			\hline
			 Schlussfolgerung & Flexibelste Alternative, Freigabe ist geringfügig langsamer als in Fall zwei, weil Blöcke noch zusammengeführt werden.\\
			\hline
			 Testfall &  Allozieren wie in Fall zwei. Freigabe von jedem zweiten Block, sodass Speicher segmentiert bleibt. Dann nochmal den hintersten Block allozieren. \\
			\hline	
		\end{tabular}
		\label{theap4}
\end{table*}

\subsection{Verifizierung}
\begin{itemize}
	\item Unter welchen Voraussetzungen ist eine Verifizierung möglich?
	\item Verifizierung bei einem ganz bestimmten Szenario
\end{itemize}

\subsection{Multiprozessorunterstützung}